Perfetto, ecco il **prompt definitivo e completo per Replit**, progettato per fornire tutto il contesto necessario allo sviluppo, con allegati i 20 file XML come esempio realistico:

---

### âœ… Prompt definitivo per Replit â€“ Cloud Probe Solution â€“ XML Batch Import

**Contesto progetto:**  
Stiamo sviluppando per Alisonic una piattaforma per il monitoraggio remoto dei serbatoi tramite sonde connesse. Ogni **sonda invia ogni 10 minuti un file XML**, contenente i dati rilevati in quel momento. Ogni XML rappresenta **una singola misurazione** di una specifica sonda, appartenente a un sito, legato a un cliente.

---

### ğŸ¯ Obiettivo di questo task

Simulare lâ€™arrivo continuo e cronologico dei file XML (esattamente come avverrÃ  in produzione) e:
1. **Importare i file nel database** in modo coerente con la logica giÃ  implementata.
2. **Popolare correttamente le entitÃ  nel database**: cliente, sito, sonda, misurazione.
3. **Evitare duplicazioni**: se una misurazione (identificata da `probe_address + timestamp`) Ã¨ giÃ  presente, NON deve essere reinserita.
4. **Verificare che la dashboard (giÃ  attiva) mostri correttamente lo storico** della sonda nella tabella â€œMeasurement Historyâ€.

---

### ğŸ§© Struttura tecnica del sistema (giÃ  presente)

- **Backend:** Python (su Replit)
- **Frontend:** Streamlit
- **Database:** PostgreSQL (unico, multi-tenant)
- Ogni misura contiene: `customer_id`, `site_id`, `address`, `timestamp`, `product`, `water`, `ullage`, `density`, `temperatures`, `alarm_status`, ecc.

Moduli giÃ  attivi nel progetto:
- `XMLParser` â†’ parsing file XML
- `DataValidator` â†’ validazione logica e tipologica dei dati
- `Database.save_measurement(data)` â†’ salva misurazione
- `Database.get_measurement_history(probe_id)` â†’ usato nella dashboard
- Dashboard e switch tra sonde funzionano correttamente

---

### ğŸ“‚ Dove si trovano i file XML per il test

Vi forniamo **20 file XML di esempio**, ciascuno con:
- Sonda `012345`
- CustomerID `22`
- SiteID `12`
- Timestamp univoco
Questi file si trovano nella cartella:
```
/mnt/data/xml_import/
```

---

### ğŸ›  Cosa deve fare lo script

1. Leggere tutti i file `.xml` presenti nella cartella `/mnt/data/xml_import/`
2. Per ogni file:
   - Eseguire il parsing XML (`XMLParser.parse_xml_file(path)`)
   - Validare i dati (`DataValidator.validate_probe_data(data)`)
   - Verificare se esiste giÃ  una misura con stesso `probe_address` + `timestamp`
     - Se esiste: saltare il file
     - Se non esiste: salvare (`Database.save_measurement(data)`)
3. Stampare un riepilogo finale:
   ```
   Importazione completata.
   Nuovi record salvati: 18
   Record giÃ  presenti: 2
   ```

---

### ğŸ§  Note importanti per l'architettura

Questo test serve anche a **simulare lâ€™uso reale del sistema**, che in produzione riceverÃ :
- **XML continui da piÃ¹ sonde** contemporaneamente
- Da **piÃ¹ clienti e piÃ¹ siti diversi**
- 24/7, ogni 10 minuti

Quindi Ã¨ essenziale che il comportamento del database e della logica sia giÃ  **scalabile e segmentato correttamente per:**
- Cliente (`customer_id`)
- Sito (`site_id`)
- Sonda (`address`)
- Timestamp (`datetime`)

---

ğŸ“¦ Allegati:
- `/mnt/data/xml_import/` contenente 20 file XML campione
- Eventuale script `batch_import_xml.py` da integrare nella logica esistente

---

âœ… Obiettivo finale: dimostrare che il sistema puÃ² ricevere file XML cronologici e popolarsi correttamente, in modo affidabile, senza duplicazioni e con corretta visualizzazione nella dashboard.

Grazie! ğŸ™Œ